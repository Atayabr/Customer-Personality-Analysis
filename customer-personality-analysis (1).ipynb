{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-04-25T05:18:06.687984Z","iopub.execute_input":"2023-04-25T05:18:06.689563Z","iopub.status.idle":"2023-04-25T05:18:06.736209Z","shell.execute_reply.started":"2023-04-25T05:18:06.689504Z","shell.execute_reply":"2023-04-25T05:18:06.734873Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Customer Segmentation","metadata":{}},{"cell_type":"markdown","source":"In this project, I will be performing an unsupervised clustering of data on the customer's records from a groceries firm's database. Customer segmentation is the practice of separating customers into groups that reflect similarities among customers in each cluster. I will divide customers into segments to optimize the significance of each customer to the business. To modify products according to distinct needs and behaviours of the customers. It also helps the business to cater to the concerns of different types of customers.","metadata":{}},{"cell_type":"markdown","source":"# Library import & Dataset","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom datetime import datetime\nimport warnings\nimport sklearn\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.decomposition import PCA\nfrom yellowbrick.cluster import KElbowVisualizer\nfrom sklearn.cluster import KMeans\nfrom sklearn.cluster import AgglomerativeClustering","metadata":{"execution":{"iopub.status.busy":"2023-04-25T05:18:06.738477Z","iopub.execute_input":"2023-04-25T05:18:06.739801Z","iopub.status.idle":"2023-04-25T05:18:12.024557Z","shell.execute_reply.started":"2023-04-25T05:18:06.739744Z","shell.execute_reply":"2023-04-25T05:18:12.023269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/customer-personality-analysis/marketing_campaign.csv\" , sep =\"\\t\")\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2023-04-25T05:18:12.026046Z","iopub.execute_input":"2023-04-25T05:18:12.027281Z","iopub.status.idle":"2023-04-25T05:18:12.241637Z","shell.execute_reply.started":"2023-04-25T05:18:12.027222Z","shell.execute_reply":"2023-04-25T05:18:12.240157Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Dataset Size:\" ,{df.shape})","metadata":{"execution":{"iopub.status.busy":"2023-04-25T05:18:12.246625Z","iopub.execute_input":"2023-04-25T05:18:12.247837Z","iopub.status.idle":"2023-04-25T05:18:12.254020Z","shell.execute_reply.started":"2023-04-25T05:18:12.247795Z","shell.execute_reply":"2023-04-25T05:18:12.253004Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"warnings.filterwarnings('ignore')  # ignore notifications\n","metadata":{"execution":{"iopub.status.busy":"2023-04-25T05:18:12.255431Z","iopub.execute_input":"2023-04-25T05:18:12.256263Z","iopub.status.idle":"2023-04-25T05:18:12.265172Z","shell.execute_reply.started":"2023-04-25T05:18:12.256224Z","shell.execute_reply":"2023-04-25T05:18:12.264226Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Features:¶\n \n# **People**\n* ID: Customer's unique identifier\n* Year_Birth: Customer's birth year\n* Education: Customer's education level\n* Marital_Status: Customer's marital status\n* Income: Customer's yearly household income\n* Kidhome: Number of children in customer's household\n* Teenhome: Number of teenagers in customer's household\n* Dt_Customer: Date of customer's enrollment with the company\n* Recency: Number of days since customer's last purchase\n* Complain: 1 if the customer complained in the last 2 years, 0 otherwise\n# **Products**\n* MntWines: Amount spent on wine in last 2 years\n* MntFruits: Amount spent on fruits in last 2 years\n* MntMeatProducts: Amount spent on meat in last 2 years\n* MntFishProducts: Amount spent on fish in last 2 years\n* MntSweetProducts: Amount spent on sweets in last 2 years\n* MntGoldProds: Amount spent on gold in last 2 years\n# **Promotion**\n* NumDealsPurchases: Number of purchases made with a discount\n* AcceptedCmp1: 1 if customer accepted the offer in the 1st campaign, 0 otherwise\n* AcceptedCmp2: 1 if customer accepted the offer in the 2nd campaign, 0 otherwise\n* AcceptedCmp3: 1 if customer accepted the offer in the 3rd campaign, 0 otherwise\n* AcceptedCmp4: 1 if customer accepted the offer in the 4th campaign, 0 otherwise\n* AcceptedCmp5: 1 if customer accepted the offer in the 5th campaign, 0 otherwise\n* Response: 1 if customer accepted the offer in the last campaign, 0 otherwise\n# **Place**\n* NumWebPurchases: Number of purchases made through the company’s website\n* NumCatalogPurchases: Number of purchases made using a catalogue\n* NumStorePurchases: Number of purchases made directly in stores\n* NumWebVisitsMonth: Number of visits to company’s website in the last month","metadata":{}},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2023-04-25T05:18:12.266958Z","iopub.execute_input":"2023-04-25T05:18:12.267303Z","iopub.status.idle":"2023-04-25T05:18:12.301744Z","shell.execute_reply.started":"2023-04-25T05:18:12.267268Z","shell.execute_reply":"2023-04-25T05:18:12.300545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.nunique()","metadata":{"execution":{"iopub.status.busy":"2023-04-25T05:18:12.303142Z","iopub.execute_input":"2023-04-25T05:18:12.303514Z","iopub.status.idle":"2023-04-25T05:18:12.320935Z","shell.execute_reply.started":"2023-04-25T05:18:12.303479Z","shell.execute_reply":"2023-04-25T05:18:12.319693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2023-04-25T05:18:12.322837Z","iopub.execute_input":"2023-04-25T05:18:12.323342Z","iopub.status.idle":"2023-04-25T05:18:12.335000Z","shell.execute_reply.started":"2023-04-25T05:18:12.323281Z","shell.execute_reply":"2023-04-25T05:18:12.333340Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.duplicated().sum()","metadata":{"execution":{"iopub.status.busy":"2023-04-25T05:18:12.337065Z","iopub.execute_input":"2023-04-25T05:18:12.337528Z","iopub.status.idle":"2023-04-25T05:18:12.359635Z","shell.execute_reply.started":"2023-04-25T05:18:12.337489Z","shell.execute_reply":"2023-04-25T05:18:12.358297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature Generation #","metadata":{}},{"cell_type":"code","source":"df[\"Age\"] = 2023 - df[\"Year_Birth\"]\n\n#client Age","metadata":{"execution":{"iopub.status.busy":"2023-04-25T05:18:12.365791Z","iopub.execute_input":"2023-04-25T05:18:12.366292Z","iopub.status.idle":"2023-04-25T05:18:12.372788Z","shell.execute_reply.started":"2023-04-25T05:18:12.366239Z","shell.execute_reply":"2023-04-25T05:18:12.371425Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_different_year():\n    registration_year = pd.to_datetime(df['Dt_Customer'], format='%d-%m-%Y').apply(lambda x: x.year)\n    current_year = datetime.now().year\n    return current_year - registration_year\n\ndf['Years_Since_Registration'] = get_different_year()  # Number of years since customer registration","metadata":{"execution":{"iopub.status.busy":"2023-04-25T05:18:12.374647Z","iopub.execute_input":"2023-04-25T05:18:12.375227Z","iopub.status.idle":"2023-04-25T05:18:12.404455Z","shell.execute_reply.started":"2023-04-25T05:18:12.375174Z","shell.execute_reply":"2023-04-25T05:18:12.403125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[\"Education\"].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-04-25T05:18:12.406160Z","iopub.execute_input":"2023-04-25T05:18:12.407314Z","iopub.status.idle":"2023-04-25T05:18:12.417050Z","shell.execute_reply.started":"2023-04-25T05:18:12.407269Z","shell.execute_reply":"2023-04-25T05:18:12.415897Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[\"Education\"] = df[\"Education\"].replace({\"Basic\":0, \"Graduation\":1, \"2n Cycle\":2, \"Master\":2, \"PhD\":3 })","metadata":{"execution":{"iopub.status.busy":"2023-04-25T05:18:12.418495Z","iopub.execute_input":"2023-04-25T05:18:12.418976Z","iopub.status.idle":"2023-04-25T05:18:12.431997Z","shell.execute_reply.started":"2023-04-25T05:18:12.418940Z","shell.execute_reply":"2023-04-25T05:18:12.430501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[\"Marital_Status\"].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-04-25T05:18:12.433769Z","iopub.execute_input":"2023-04-25T05:18:12.434473Z","iopub.status.idle":"2023-04-25T05:18:12.447443Z","shell.execute_reply.started":"2023-04-25T05:18:12.434430Z","shell.execute_reply":"2023-04-25T05:18:12.445936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[\"Marital_Status\"] = df[\"Marital_Status\"].replace({\"Married\":2, \"Together\":2, \"Single\":1, \"Divorced\":1, \"Widow\":1, \"Alone\":1, \"Absurd\":1, \"YOLO\":1 })","metadata":{"execution":{"iopub.status.busy":"2023-04-25T05:18:12.451380Z","iopub.execute_input":"2023-04-25T05:18:12.451817Z","iopub.status.idle":"2023-04-25T05:18:12.462171Z","shell.execute_reply.started":"2023-04-25T05:18:12.451779Z","shell.execute_reply":"2023-04-25T05:18:12.461038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[\"Family_Size\"] = df[\"Marital_Status\"] + df[\"Kidhome\"] + df[\"Teenhome\"]\n\n# Total number of people in the family\n","metadata":{"execution":{"iopub.status.busy":"2023-04-25T05:18:12.463835Z","iopub.execute_input":"2023-04-25T05:18:12.464528Z","iopub.status.idle":"2023-04-25T05:18:12.472341Z","shell.execute_reply.started":"2023-04-25T05:18:12.464480Z","shell.execute_reply":"2023-04-25T05:18:12.470799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[\"Sum_Mnt\"] = df[\"MntWines\"] + df[\"MntFruits\"] + df[\"MntMeatProducts\"] + df[\"MntFishProducts\"] + df[\"MntSweetProducts\"] + df[\"MntGoldProds\"]\n\n# Total amount spent on products","metadata":{"execution":{"iopub.status.busy":"2023-04-25T05:18:12.474323Z","iopub.execute_input":"2023-04-25T05:18:12.474753Z","iopub.status.idle":"2023-04-25T05:18:12.486772Z","shell.execute_reply.started":"2023-04-25T05:18:12.474714Z","shell.execute_reply":"2023-04-25T05:18:12.485384Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['Num_Accepted_Cmp'] = df[\"AcceptedCmp1\"] + df[\"AcceptedCmp2\"] + df[\"AcceptedCmp3\"] + df[\"AcceptedCmp4\"] + df[\"AcceptedCmp5\"] + df[\"Response\"]\n\n# Number of companies in which the client accepted the offer\n","metadata":{"execution":{"iopub.status.busy":"2023-04-25T05:18:12.488728Z","iopub.execute_input":"2023-04-25T05:18:12.489498Z","iopub.status.idle":"2023-04-25T05:18:12.501836Z","shell.execute_reply.started":"2023-04-25T05:18:12.489433Z","shell.execute_reply":"2023-04-25T05:18:12.500380Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['Num_Total_Purchases'] = df[\"NumWebPurchases\"] + df[\"NumCatalogPurchases\"] + df[\"NumStorePurchases\"] +df[\"NumDealsPurchases\"]\n\n# Total number of purchases","metadata":{"execution":{"iopub.status.busy":"2023-04-25T05:18:12.503483Z","iopub.execute_input":"2023-04-25T05:18:12.504243Z","iopub.status.idle":"2023-04-25T05:18:12.511152Z","shell.execute_reply.started":"2023-04-25T05:18:12.504199Z","shell.execute_reply":"2023-04-25T05:18:12.510096Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# let's look at the correlation matrix:¶\n# ","metadata":{}},{"cell_type":"code","source":"to_corr = [\"Age\",\"Education\", \"Marital_Status\", \"Income\",\"Kidhome\", \"Teenhome\", \"Years_Since_Registration\",\n          \"Recency\", \"MntWines\", \"MntFruits\", \"MntMeatProducts\", \"MntFishProducts\", \"MntSweetProducts\", \n           \"MntGoldProds\", \"NumDealsPurchases\", \"NumWebPurchases\", \"NumCatalogPurchases\", \"NumStorePurchases\",\n          \"NumWebVisitsMonth\", \"AcceptedCmp3\", \"AcceptedCmp1\", \"AcceptedCmp2\", \"AcceptedCmp4\", \"AcceptedCmp5\", \n           \"Complain\", \"Response\", \"Num_Total_Purchases\", \"Num_Accepted_Cmp\", \"Sum_Mnt\", \"Family_Size\"]\n\ncmap = sns.diverging_palette(220, 10, as_cmap=True)\nmatrix = np.triu(df[to_corr].corr())\nplt.figure(figsize=(25, 14))\nplt.title('Correlation matrix', fontsize=18)\nsns.heatmap(df[to_corr].corr(), annot=True,\n            fmt='.1f', vmin=-0.4, center=0, cmap=cmap, mask=matrix)\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-04-25T05:18:12.513207Z","iopub.execute_input":"2023-04-25T05:18:12.514065Z","iopub.status.idle":"2023-04-25T05:18:15.031193Z","shell.execute_reply.started":"2023-04-25T05:18:12.514014Z","shell.execute_reply":"2023-04-25T05:18:15.030234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# look at the distributions of quantitative variables:¶\n# ","metadata":{}},{"cell_type":"code","source":"to_plot = ['Income', 'Recency', 'Age', 'Years_Since_Registration', 'Sum_Mnt',\n           'Num_Total_Purchases', 'Marital_Status']\nsns.pairplot(df[to_plot], hue='Marital_Status', palette='Set1')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-04-25T05:18:15.032560Z","iopub.execute_input":"2023-04-25T05:18:15.033101Z","iopub.status.idle":"2023-04-25T05:18:29.020867Z","shell.execute_reply.started":"2023-04-25T05:18:15.033065Z","shell.execute_reply":"2023-04-25T05:18:29.019493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Clearly, there are a few outliers in the Income and Age features. I will be deleting the outliers in the data.","metadata":{}},{"cell_type":"markdown","source":"# Data Cleaning","metadata":{}},{"cell_type":"code","source":"df.dropna(inplace = True)\n\n# Removed objects with gaps in income","metadata":{"execution":{"iopub.status.busy":"2023-04-25T05:18:29.023212Z","iopub.execute_input":"2023-04-25T05:18:29.023813Z","iopub.status.idle":"2023-04-25T05:18:29.033695Z","shell.execute_reply.started":"2023-04-25T05:18:29.023739Z","shell.execute_reply":"2023-04-25T05:18:29.032198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def remove_outliers(data: pd.DataFrame, column: str) -> pd.Series:\n    q3, q1 = np.nanpercentile(data[column], [75, 25])\n    iqr = q3 - q1\n    upper_bound = q3 + 1.5 * iqr\n    lower_bound = q1 - 1.5 * iqr\n    data = data[(data[column] > lower_bound) & (data[column] < upper_bound)]\n\n    return data\n\ndf = remove_outliers(df, 'Age')\ndf = remove_outliers(df, \"Income\")","metadata":{"execution":{"iopub.status.busy":"2023-04-25T05:18:29.035700Z","iopub.execute_input":"2023-04-25T05:18:29.036451Z","iopub.status.idle":"2023-04-25T05:18:29.051838Z","shell.execute_reply.started":"2023-04-25T05:18:29.036405Z","shell.execute_reply":"2023-04-25T05:18:29.050354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.drop([\"Year_Birth\", \"ID\", \"Z_CostContact\", \"Z_Revenue\", \"Dt_Customer\"], axis =1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-04-25T05:18:29.053447Z","iopub.execute_input":"2023-04-25T05:18:29.053842Z","iopub.status.idle":"2023-04-25T05:18:29.063675Z","shell.execute_reply.started":"2023-04-25T05:18:29.053801Z","shell.execute_reply":"2023-04-25T05:18:29.062225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2023-04-25T05:18:29.065877Z","iopub.execute_input":"2023-04-25T05:18:29.066664Z","iopub.status.idle":"2023-04-25T05:18:29.096282Z","shell.execute_reply.started":"2023-04-25T05:18:29.066585Z","shell.execute_reply":"2023-04-25T05:18:29.094765Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"execution":{"iopub.status.busy":"2023-04-25T05:18:29.097869Z","iopub.execute_input":"2023-04-25T05:18:29.098268Z","iopub.status.idle":"2023-04-25T05:18:29.108727Z","shell.execute_reply.started":"2023-04-25T05:18:29.098221Z","shell.execute_reply":"2023-04-25T05:18:29.107368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2023-04-25T05:18:29.110799Z","iopub.execute_input":"2023-04-25T05:18:29.111174Z","iopub.status.idle":"2023-04-25T05:18:29.129274Z","shell.execute_reply.started":"2023-04-25T05:18:29.111136Z","shell.execute_reply":"2023-04-25T05:18:29.128315Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data scaling (Normalization | Standartization)","metadata":{}},{"cell_type":"markdown","source":"Data scaling is necessary to bring all features to the same scale. If this is not done, then the attention of the algorithm will be attracted to features that include large values (this is bad)\nIn this work, normalization will be used as data scaling (as a result of normalization, all features are in the range from 0 to 1)","metadata":{}},{"cell_type":"code","source":"def scaling_func(df):\n    mms = MinMaxScaler()\n    return pd.DataFrame(data = mms.fit_transform(df), columns = df.columns)\n\n\ndf_scaled = scaling_func(df)\n\ndf_scaled.index = df.index\n\n# for convenient work with dataframes\n\n","metadata":{"execution":{"iopub.status.busy":"2023-04-25T05:18:29.135258Z","iopub.execute_input":"2023-04-25T05:18:29.135895Z","iopub.status.idle":"2023-04-25T05:18:29.147206Z","shell.execute_reply.started":"2023-04-25T05:18:29.135857Z","shell.execute_reply":"2023-04-25T05:18:29.146123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dimensionality reduction\n# ","metadata":{}},{"cell_type":"markdown","source":"**The dimensionality reduction problem is used in the following situations:**\n* There are a lot of features in the dataset, and we want to reduce their number, leaving as much information as possible\n* We have many features in the dataset, and we want to visualize the data (for example, in 3D space)\n* Solving the problem of multicollinearity\n\nThere are many different options for dimensionality reduction, which are based on different methods, for example:\n\n* Principal component analysis (PCA)\n* Uniform Manifold Approximation and Projection (UMAP)\n* t-distributed Stochastic Neighbor Embedding (t-SNE)\n* Locally-Linear Embedding (LLE)\n* Multidimensional Scaling (MDS)\n\nThe most commonly used dimensionality reduction algorithm is PCA, and we also use it in this work.\n\nEssentially, in PCA we make a transition from one variable space to another, with the new space containing fewer variables (n_component), where the new variables are uncorrelated and are the weighted sum of the old variables.\n\nAs a result we get m variables: {PC1, PC2, PC3... PCm} , where PC1 will receive the most information(maximum sample variance), PC2 - less, and so on (A variable is considered informative if it has a high sample variance).\n\n8 components will be used in this work.","metadata":{}},{"cell_type":"code","source":"#Initiating PCA to reduce dimentions aka features to 3\npca = PCA(n_components=3)\npca.fit(df_scaled)\nPCA_ds = pd.DataFrame(pca.transform(df_scaled), columns=([\"col1\",\"col2\", \"col3\"]))\nPCA_ds.describe().T","metadata":{"execution":{"iopub.status.busy":"2023-04-25T05:18:29.148866Z","iopub.execute_input":"2023-04-25T05:18:29.149512Z","iopub.status.idle":"2023-04-25T05:18:29.220819Z","shell.execute_reply.started":"2023-04-25T05:18:29.149472Z","shell.execute_reply":"2023-04-25T05:18:29.218908Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#A 3D Projection Of Data In The Reduced Dimension\nx =PCA_ds[\"col1\"]\ny =PCA_ds[\"col2\"]\nz =PCA_ds[\"col3\"]\n#To plot\nfig = plt.figure(figsize=(10,8))\nax = fig.add_subplot(111, projection=\"3d\")\nax.scatter(x,y,z, c=\"maroon\", marker=\"o\" )\nax.set_title(\"A 3D Projection Of Data In The Reduced Dimension\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-04-25T05:18:29.223645Z","iopub.execute_input":"2023-04-25T05:18:29.224888Z","iopub.status.idle":"2023-04-25T05:18:29.656925Z","shell.execute_reply.started":"2023-04-25T05:18:29.224805Z","shell.execute_reply":"2023-04-25T05:18:29.655482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Clustering","metadata":{}},{"cell_type":"markdown","source":"* Feature Generation\n* Data Cleaning\n* Data Scaling (normalization)\n* Dimensionality Reduction (PCA)\n* Clustering ","metadata":{}},{"cell_type":"markdown","source":"Now that I have reduced the attributes to three dimensions, I will be performing clustering via Agglomerative clustering. Agglomerative clustering is a hierarchical clustering method. It involves merging examples until the desired number of clusters is achieved.\n\n**Steps involved in the Clustering**\n\n* Elbow Method to determine the number of clusters to be formed\n* Clustering via Agglomerative Clustering\n* Examining the clusters formed via scatter plot","metadata":{}},{"cell_type":"code","source":"print('Elbow Method to determine the number of clusters to be formed:')\n\nElbow_M = KElbowVisualizer(KMeans(), k=10)\nElbow_M.fit(PCA_ds)\nElbow_M.show()","metadata":{"execution":{"iopub.status.busy":"2023-04-25T05:18:29.658949Z","iopub.execute_input":"2023-04-25T05:18:29.659460Z","iopub.status.idle":"2023-04-25T05:18:31.142426Z","shell.execute_reply.started":"2023-04-25T05:18:29.659404Z","shell.execute_reply":"2023-04-25T05:18:31.140942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The above cell indicates that five will be an optimal number of clusters for this data. Next, we will be fitting the Agglomerative Clustering Model to get the final clusters.","metadata":{}},{"cell_type":"code","source":"#Initiating the Agglomerative Clustering model \nAC = AgglomerativeClustering(n_clusters=5)\n# fit model and predict clusters\nyhat_AC = AC.fit_predict(PCA_ds)\nPCA_ds[\"Clusters\"] = yhat_AC\n#Adding the Clusters feature to the orignal dataframe.\ndf[\"Clusters\"]= yhat_AC","metadata":{"execution":{"iopub.status.busy":"2023-04-25T05:18:31.143768Z","iopub.execute_input":"2023-04-25T05:18:31.144149Z","iopub.status.idle":"2023-04-25T05:18:31.301929Z","shell.execute_reply.started":"2023-04-25T05:18:31.144112Z","shell.execute_reply":"2023-04-25T05:18:31.300891Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"To examine the clusters formed let's have a look at the 3-D distribution of the clusters.","metadata":{}},{"cell_type":"code","source":"#Plotting the clusters\nfig = plt.figure(figsize=(10,8))\nax = plt.subplot(111, projection='3d', label=\"bla\")\nax.scatter(x, y, z, s=40, c=PCA_ds[\"Clusters\"], marker='o', cmap = cmap )\nax.set_title(\"The Plot Of The Clusters\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-04-25T05:18:31.303176Z","iopub.execute_input":"2023-04-25T05:18:31.304286Z","iopub.status.idle":"2023-04-25T05:18:31.599643Z","shell.execute_reply.started":"2023-04-25T05:18:31.304244Z","shell.execute_reply":"2023-04-25T05:18:31.598313Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Plotting countplot of clusters\npal = [\"#682F2F\",\"#B9C0C9\", \"#9F8A78\",\"#F3AB60\", \"#E75702\"]\npl = sns.countplot(x=df[\"Clusters\"], palette= pal)\npl.set_title(\"Distribution Of The Clusters\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-04-25T05:18:31.601657Z","iopub.execute_input":"2023-04-25T05:18:31.602264Z","iopub.status.idle":"2023-04-25T05:18:31.991169Z","shell.execute_reply.started":"2023-04-25T05:18:31.602210Z","shell.execute_reply":"2023-04-25T05:18:31.990210Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pl = sns.scatterplot(data = df, x = df[\"Sum_Mnt\"], y=df[\"Income\"], hue=df[\"Clusters\"], palette = pal)\npl.set_title(\"Cluster's Profile Based On Income And Spending\")\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-04-25T05:18:31.994072Z","iopub.execute_input":"2023-04-25T05:18:31.995210Z","iopub.status.idle":"2023-04-25T05:18:32.474200Z","shell.execute_reply.started":"2023-04-25T05:18:31.995133Z","shell.execute_reply":"2023-04-25T05:18:32.473198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Income vs spending plot shows the clusters pattern\n\ngroup 0:low spending & low income\n\ngroup 1: high spending & high income\n\ngroup 2: low spending & low income\n\ngroup 3: high spending & high income\n\ngroup 4:high dispersion","metadata":{}},{"cell_type":"markdown","source":"Next, I will be looking at the detailed distribution of clusters as per the various products in the data. Namely: Wines, Fruits, Meat, Fish, Sweets and Gold","metadata":{}},{"cell_type":"code","source":"plt.figure()\npl=sns.swarmplot(x=df[\"Clusters\"], y=df[\"Sum_Mnt\"], color= \"#CBEDDD\", alpha=0.5 )\npl=sns.boxenplot(x=df[\"Clusters\"], y=df[\"Sum_Mnt\"], palette=pal)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-04-25T05:18:32.475778Z","iopub.execute_input":"2023-04-25T05:18:32.476127Z","iopub.status.idle":"2023-04-25T05:18:49.566388Z","shell.execute_reply.started":"2023-04-25T05:18:32.476087Z","shell.execute_reply":"2023-04-25T05:18:49.565056Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the above plot, it can be clearly seen that cluster 1 is our biggest set of customers ","metadata":{}},{"cell_type":"markdown","source":"Let us next explore how did our campaigns do in the past.\n\n","metadata":{}},{"cell_type":"code","source":"#Creating a feature to get a sum of accepted promotions \n#Plotting count of total campaign accepted.\n\nplt.figure()\npl = sns.countplot(x=df[\"Num_Accepted_Cmp\"], hue=df[\"Clusters\"], palette=pal)\npl.set_title(\"Count Of Promotion Accepted\")\npl.set_xlabel(\"Number Of Total Accepted Promotions\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-04-25T05:18:49.568037Z","iopub.execute_input":"2023-04-25T05:18:49.568466Z","iopub.status.idle":"2023-04-25T05:18:49.872819Z","shell.execute_reply.started":"2023-04-25T05:18:49.568425Z","shell.execute_reply":"2023-04-25T05:18:49.871358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There has not been an overwhelming response to the campaigns so far. Very few participants overall. Moreover, no one part take in all 5 of them. Perhaps better-targeted and well-planned campaigns are required to boost sales.","metadata":{}},{"cell_type":"code","source":"#Plotting the number of deals purchased\nplt.figure()\npl=sns.boxenplot(y=df[\"NumDealsPurchases\"],x=df[\"Clusters\"], palette= pal)\npl.set_title(\"Number of Deals Purchased\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-04-25T05:18:49.874418Z","iopub.execute_input":"2023-04-25T05:18:49.874848Z","iopub.status.idle":"2023-04-25T05:18:50.114953Z","shell.execute_reply.started":"2023-04-25T05:18:49.874801Z","shell.execute_reply":"2023-04-25T05:18:50.113921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Unlike campaigns, the deals offered did well. It has best outcome with cluster 2. However, our star customers cluster 1 are not much into the deals","metadata":{}},{"cell_type":"markdown","source":"# PROFILING #","metadata":{}},{"cell_type":"markdown","source":"Now that we have formed the clusters and looked at their purchasing habits. Let us see who all are there in these clusters. For that, we will be profiling the clusters formed and come to a conclusion about who is our star customer and who needs more attention from the retail store's marketing team.\n\nTo decide that I will be plotting some of the features that are indicative of the customer's personal traits in light of the cluster they are in. On the basis of the outcomes, I will be arriving at the conclusions.","metadata":{}},{"cell_type":"code","source":"personal = [\"Education\", \"Marital_Status\", \"Income\", \"Kidhome\", \"Teenhome\", \"Age\", \"Family_Size\"]\n\nfor i in personal:\n    plt.figure()\n    sns.jointplot(x = df[i], y=df[\"Sum_Mnt\"], hue=df[\"Clusters\"], kind = \"kde\", palette = pal)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-04-25T05:18:50.116660Z","iopub.execute_input":"2023-04-25T05:18:50.117911Z","iopub.status.idle":"2023-04-25T05:19:03.758099Z","shell.execute_reply.started":"2023-04-25T05:18:50.117852Z","shell.execute_reply":"2023-04-25T05:19:03.756864Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"CONCLUSION\n\nIn this project, I performed unsupervised clustering. I did use dimensionality reduction followed by agglomerative clustering. I came up with 5 clusters and further used them in profiling customers in clusters according to their family structures and income/spending. This can be used in planning better marketing strategies.","metadata":{}},{"cell_type":"markdown","source":"# As a result of cluster analysis, we received three groups of buyers (clusters):¶\n# ","metadata":{}},{"cell_type":"markdown","source":"about cluster 0:\n\n* most of them are the parent\n* at the max have 4 members in the family\n* most have a teenager at home\n* lower than average income\n\nabout cluster 1:\n\n* most of them are single\n* at the max have 3 members in the family\n* a high-income group\n\naboout cluster 2:\n\n* a lower-income group\n* they are  a parent\n* at the max have 5 members in the family\n* lower than-average perches\n\naboout cluster 3:\n\n* a high-income group\n* upper than-average income\n* upper than-average perches\n* most of them are the parent\n\naboout cluster 4:\n\n* Most of the members of this group are 1 to 3 people\n* upper than-average income\n* upper than-average perches","metadata":{}}]}